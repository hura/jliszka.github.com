
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Climbing the probability distribution ladder</title>
    <meta name="description" content="">
    <meta name="author" content="Jason Liszka">

    <!-- Enable responsive viewport -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Le HTML5 shim, for IE6-8 support of HTML elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le styles -->
    <link href="/assets/themes/twitter/bootstrap/css/bootstrap.2.2.2.min.css" rel="stylesheet">
    <link href="/assets/themes/twitter/css/style.css?body=1" rel="stylesheet" type="text/css" media="all">
    <link href="/assets/themes/twitter/css/pygment.css" rel="stylesheet" type="text/css" media="all">

    <!-- Le fav and touch icons -->
  <!-- Update these with your own images
    <link rel="shortcut icon" href="images/favicon.ico">
    <link rel="apple-touch-icon" href="images/apple-touch-icon.png">
    <link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
    <link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
  -->

    <!-- atom & rss feed -->
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="Sitewide ATOM Feed">
    <link href="/rss.xml" type="application/rss+xml" rel="alternate" title="Sitewide RSS Feed">
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  </head>

  <body>
    <div class="navbar">
      <div class="navbar-inner">
        <div class="container-narrow">
          <a class="brand" href="/">A Gentleman and a Scala</a>
          <ul class="nav">
            
            
            


  
    
      
      	
      	<li><a href="/archive.html">Archive</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
      	
      	<li><a href="/tags.html">Tags</a></li>
      	
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  
    
      
    
  



          </ul>
        </div>
      </div>
    </div>

    <div class="container-narrow">

      <div class="content">
        
<div class="page-header">
  <h1>Climbing the probability distribution ladder </h1>
</div>

<div class="row-fluid post-full">
  <div class="span12">
    <div class="date">
      <span>09 August 2013</span>
    </div>
    <div class="content">
      <p>In my <a href=''>last post</a> I created a tool for constructing probability distributions. I started with the uniform distribution and derived the Bernoulli and normal distributions from it.</p>

<p>In this post I&#8217;ll construct some more common distributions in the same manner.</p>

<h3 id='exponential_and_pareto_distributions'>Exponential and Pareto distributions</h3>

<p>If <script type='math/tex'>X</script> is a uniformly distributed random variable, then <script type='math/tex'>-log(X)/\lambda</script> is called the <a href='http://en.wikipedia.org/wiki/Exponential_distribution'>exponential distribution</a>. The parameter <script type='math/tex'>\lambda</script> is just a scaling factor. In code:</p>
<div class='highlight'><pre><code class='scala'><span class='k'>def</span> <span class='n'>exponential</span><span class='o'>(</span><span class='n'>l</span><span class='k'>:</span> <span class='kt'>Double</span><span class='o'>)</span><span class='k'>:</span> <span class='kt'>Distribution</span><span class='o'>[</span><span class='kt'>Double</span><span class='o'>]</span> <span class='k'>=</span> <span class='o'>{</span>
  <span class='k'>for</span> <span class='o'>{</span>
    <span class='n'>x</span> <span class='k'>&lt;-</span> <span class='n'>uniform</span>
  <span class='o'>}</span> <span class='k'>yield</span> <span class='n'>math</span><span class='o'>.</span><span class='n'>log</span><span class='o'>(</span><span class='n'>x</span><span class='o'>)</span> <span class='o'>*</span> <span class='o'>(-</span><span class='mi'>1</span><span class='o'>/</span><span class='n'>l</span><span class='o'>)</span>
<span class='o'>}</span>
</code></pre></div>
<p>It looks like this:</p>

<pre><code>scala&gt; exponential(1).bucketedHist(0, 8, 16, roundDown = true)
 0.0 39.40% #######################################
 0.5 23.15% #######################
 1.0 15.11% ###############
 1.5  9.13% #########
 2.0  4.93% ####
 2.5  3.32% ###
 3.0  1.84% #
 3.5  1.19% #
 4.0  0.71% 
 4.5  0.53% 
 5.0  0.32% 
 5.5  0.15% 
 6.0  0.07% 
 6.5  0.07% 
 7.0  0.03% 
 7.5  0.03% 
 8.0  0.01% </code></pre>

<p>It seems backwards to me that the exponential distribution is implemented using a logarithm. It probably has something to do with this particular technique of constructing distributions. I&#8217;m describing where to put each piece of probability mass (here, by taking the log of each sample) rather than describing how much probability mass lives at each value of <script type='math/tex'>x</script> (for the exponential distribution, <script type='math/tex'>\lambda e^{-\lambda x}</script> lives at <script type='math/tex'>x</script>).</p>

<p>We can construct the <a href='http://en.wikipedia.org/wiki/Pareto_distribution'>Pareto distribution</a> from the uniform distribution in a similar way. If <script type='math/tex'>X</script> is a uniformly distributed random variable, then <script type='math/tex'>x_m X^{-1/\alpha}</script> is a Pareto-distributed random variable. The parameter <script type='math/tex'>x_m</script> is the minimum value the distribution can take, and <script type='math/tex'>\alpha</script> is a factor that determines how spread out the distribution is. In code:</p>
<div class='highlight'><pre><code class='scala'><span class='k'>def</span> <span class='n'>pareto</span><span class='o'>(</span><span class='n'>a</span><span class='k'>:</span> <span class='kt'>Double</span><span class='o'>,</span> <span class='n'>xm</span><span class='k'>:</span> <span class='kt'>Double</span> <span class='o'>=</span> <span class='mf'>1.0</span><span class='o'>)</span><span class='k'>:</span> <span class='kt'>Distribution</span><span class='o'>[</span><span class='kt'>Double</span><span class='o'>]</span> <span class='k'>=</span> <span class='o'>{</span>
  <span class='k'>for</span> <span class='o'>{</span>
    <span class='n'>x</span> <span class='k'>&lt;-</span> <span class='n'>uniform</span>
  <span class='o'>}</span> <span class='k'>yield</span> <span class='n'>xm</span> <span class='o'>*</span> <span class='n'>math</span><span class='o'>.</span><span class='n'>pow</span><span class='o'>(</span><span class='n'>x</span><span class='o'>,</span> <span class='o'>-</span><span class='mi'>1</span><span class='o'>/</span><span class='n'>a</span><span class='o'>)</span>
<span class='o'>}</span>
</code></pre></div>
<p>It looks like this:</p>

<pre><code>scala&gt; pareto(1).bucketedHist(1, 10, 18, roundDown = true)
 1.0 37.60% #####################################
 1.5 17.59% #################
 2.0 10.52% ##########
 2.5  7.61% #######
 3.0  5.43% #####
 3.5  4.04% ####
 4.0  2.85% ##
 4.5  2.64% ##
 5.0  1.61% #
 5.5  1.77% #
 6.0  1.37% #
 6.5  1.10% #
 7.0  1.06% #
 7.5  0.98% 
 8.0  0.90% 
 8.5  0.83% 
 9.0  0.68% 
 9.5  0.56% 
10.0  0.39% </code></pre>

<p>Hm, the implementations of <code>pareto</code> and <code>exponential</code> look pretty similar. It&#8217;s more obvious if I rewrite <code>exponential</code> slightly, moving the product inside the log.</p>
<div class='highlight'><pre><code class='scala'><span class='k'>def</span> <span class='n'>exponential</span><span class='o'>(</span><span class='n'>l</span><span class='k'>:</span> <span class='kt'>Double</span><span class='o'>)</span><span class='k'>:</span> <span class='kt'>Distribution</span><span class='o'>[</span><span class='kt'>Double</span><span class='o'>]</span> <span class='k'>=</span> <span class='o'>{</span>
  <span class='k'>for</span> <span class='o'>{</span>
    <span class='n'>x</span> <span class='k'>&lt;-</span> <span class='n'>uniform</span>
  <span class='o'>}</span> <span class='k'>yield</span> <span class='n'>math</span><span class='o'>.</span><span class='n'>log</span><span class='o'>(</span><span class='n'>math</span><span class='o'>.</span><span class='n'>pow</span><span class='o'>(</span><span class='n'>x</span><span class='o'>,</span> <span class='o'>-</span><span class='mi'>1</span><span class='o'>/</span><span class='n'>l</span><span class='o'>))</span>
<span class='o'>}</span>
</code></pre></div>
<p>And now it looks like <code>exponential</code> is just the log of <code>pareto</code>. Let&#8217;s check.</p>

<pre><code>scala&gt; pareto(1).map(math.log).bucketedHist(0, 8, 16, roundDown = true)
 0.0 38.76% ######################################
 0.5 24.28% ########################
 1.0 14.47% ##############
 1.5  9.09% #########
 2.0  5.10% #####
 2.5  3.29% ###
 3.0  1.92% #
 3.5  1.29% #
 4.0  0.77% 
 4.5  0.43% 
 5.0  0.22% 
 5.5  0.14% 
 6.0  0.09% 
 6.5  0.04% 
 7.0  0.02% 
 7.5  0.04% 
 8.0  0.04% </code></pre>

<p>Yep, pretty close! But you wouldn&#8217;t know how closely they are related by looking at the probabily density functions.</p>

<p>Pareto:</p>
<script type='math/tex; mode=display'>
f_\alpha(x) = \frac{\alpha}{x^{\alpha+1}}
</script>
<p>Exponential:</p>
<script type='math/tex; mode=display'>
f_\lambda(x) = \lambda e^{-\lambda x}
</script>
<h3 id='chisquared_and_students_tdistribution'>Chi-squared and Student&#8217;s <em>t</em>-distribution</h3>

<p>A <a href='http://en.wikipedia.org/wiki/Chi-squared_distribution'>Chi-squared distribution</a> can be constructed by squaring and then summing several normal distributions. It is parameterized by the number of degrees of freedom, <code>df</code>, which just indicates how many squared normal distributions to sum up. Here&#8217;s the code:</p>
<div class='highlight'><pre><code class='scala'><span class='k'>def</span> <span class='n'>chi2</span><span class='o'>(</span><span class='n'>df</span><span class='k'>:</span> <span class='kt'>Int</span><span class='o'>)</span><span class='k'>:</span> <span class='kt'>Distribution</span><span class='o'>[</span><span class='kt'>Double</span><span class='o'>]</span> <span class='k'>=</span> <span class='o'>{</span>
  <span class='n'>normal</span><span class='o'>.</span><span class='n'>map</span><span class='o'>(</span><span class='n'>x</span> <span class='k'>=&gt;</span> <span class='n'>x</span><span class='o'>*</span><span class='n'>x</span><span class='o'>).</span><span class='n'>repeat</span><span class='o'>(</span><span class='n'>df</span><span class='o'>).</span><span class='n'>map</span><span class='o'>(</span><span class='k'>_</span><span class='o'>.</span><span class='n'>sum</span><span class='o'>)</span>
<span class='o'>}</span>
</code></pre></div>
<p>This is a lot easier to look at than its probability density function for <script type='math/tex'>k</script> degrees of freedom:</p>
<script type='math/tex; mode=display'>
f_k(x) = \frac{x^{(k/2)-1}e^{-x/2}}{2^{k/2}\Gamma(\frac{k}{2})}
</script>
<p>Gross. I&#8217;m not going to even get into what <script type='math/tex'>\Gamma</script> is.</p>

<p>OK here&#8217;s what it looks like for different degrees of freedom:</p>

<pre><code>scala&gt; chi2(1).bucketedHist(0, 10, 10, roundDown = true)
 0.0 68.20% ####################################################################
 1.0 15.49% ###############
 2.0  7.67% #######
 3.0  3.83% ###
 4.0  2.07% ##
 5.0  1.30% #
 6.0  0.66% 
 7.0  0.42% 
 8.0  0.26% 
 9.0  0.10% 
10.0  0.00% 

scala&gt; chi2(5).bucketedHist(0, 15, 15, roundDown = true)
 0.0  3.84% ###
 1.0 11.48% ###########
 2.0 14.71% ##############
 3.0 15.07% ###############
 4.0 13.67% #############
 5.0 10.83% ##########
 6.0  8.75% ########
 7.0  6.43% ######
 8.0  4.99% ####
 9.0  3.51% ###
10.0  2.43% ##
11.0  1.64% #
12.0  1.22% #
13.0  0.85% 
14.0  0.59% 
15.0  0.00% </code></pre>

<p>If <script type='math/tex'>Z</script> is a normally distributed random variable and <script type='math/tex'>V</script> is a Chi-squared random variable with <script type='math/tex'>k</script> degrees of freedom, then <script type='math/tex'>Z * \sqrt{k/V}</script> is a random variable distributed according to the <a href='http://en.wikipedia.org/wiki/Student&apos;s_t-distribution'>Student&#8217;s <em>t</em>-distribution</a>.</p>

<p>Here&#8217;s the code:</p>
<div class='highlight'><pre><code class='scala'><span class='k'>def</span> <span class='n'>students_t</span><span class='o'>(</span><span class='n'>df</span><span class='k'>:</span> <span class='kt'>Int</span><span class='o'>)</span><span class='k'>:</span> <span class='kt'>Distribution</span><span class='o'>[</span><span class='kt'>Double</span><span class='o'>]</span> <span class='k'>=</span> <span class='o'>{</span>
  <span class='k'>for</span> <span class='o'>{</span>
    <span class='n'>z</span> <span class='k'>&lt;-</span> <span class='n'>normal</span>
    <span class='n'>v</span> <span class='k'>&lt;-</span> <span class='n'>chi2</span><span class='o'>(</span><span class='n'>df</span><span class='o'>)</span>
  <span class='o'>}</span> <span class='k'>yield</span> <span class='n'>z</span> <span class='o'>*</span> <span class='n'>math</span><span class='o'>.</span><span class='n'>sqrt</span><span class='o'>(</span><span class='n'>df</span> <span class='o'>/</span> <span class='n'>v</span><span class='o'>)</span>
<span class='o'>}</span>
</code></pre></div>
<p>The closed-form probability density function is too gross to even consider. Here&#8217;s a plot though:</p>

<pre><code>scala&gt; students_t(3).bucketedHist(-5, 5, 20)
-5.0  0.12% 
-4.5  0.38% 
-4.0  0.51% 
-3.5  0.63% 
-3.0  1.41% #
-2.5  2.24% ##
-2.0  3.72% ###
-1.5  5.89% #####
-1.0 10.03% ##########
-0.5 15.90% ###############
 0.0 18.38% ##################
 0.5 15.88% ###############
 1.0 11.01% ###########
 1.5  5.83% #####
 2.0  3.37% ###
 2.5  2.07% ##
 3.0  1.13% #
 3.5  0.62% 
 4.0  0.49% 
 4.5  0.26% 
 5.0  0.14% </code></pre>

<p>It looks a lot like the normal distribution, and in fact as the degrees of freedom goes up, it becomes a better and better approximation to it. At smaller degrees of freedom, though, there is more probability mass in the tails.</p>

<h3 id='the_binomial_and_geometric_distributions'>The Binomial and Geometric distributions</h3>

<p>I&#8217;m going to switch gears for a minute and look at two discrete distributions. These are constructed from the Bernoulli distribution (a biased coin flip) rather than the uniform or normal distribution. Although recall that the Bernoulli distribution itself can be <a href=''>constructed from the uniform distribution</a>.</p>

<p>The <a href='http://en.wikipedia.org/wiki/Binomial_distribution'>binomial distribution</a> can be modeled as the number of successes you will see in <script type='math/tex'>n</script> Bernoulli trials with bias <script type='math/tex'>p</script>. In other words, if I flip a fair coin 20 times, how many times will it come up heads? Let&#8217;s see:</p>
<div class='highlight'><pre><code class='scala'><span class='k'>def</span> <span class='n'>binomial</span><span class='o'>(</span><span class='n'>p</span><span class='k'>:</span> <span class='kt'>Double</span><span class='o'>,</span> <span class='n'>n</span><span class='k'>:</span> <span class='kt'>Int</span><span class='o'>)</span><span class='k'>:</span> <span class='kt'>Distribution</span><span class='o'>[</span><span class='kt'>Int</span><span class='o'>]</span> <span class='k'>=</span> <span class='o'>{</span>
  <span class='n'>bernoulli</span><span class='o'>(</span><span class='n'>p</span><span class='o'>).</span><span class='n'>repeat</span><span class='o'>(</span><span class='n'>n</span><span class='o'>).</span><span class='n'>map</span><span class='o'>(</span><span class='k'>_</span><span class='o'>.</span><span class='n'>count</span><span class='o'>(</span><span class='k'>_</span> <span class='o'>==</span> <span class='kc'>true</span><span class='o'>))</span>
<span class='o'>}</span>
</code></pre></div>
<pre><code>scala&gt; binomial(0.5, 20).hist
 2  0.02% 
 3  0.11% 
 4  0.46% 
 5  1.33% #
 6  3.81% ###
 7  7.35% #######
 8 11.73% ###########
 9 15.84% ###############
10 18.05% ##################
11 16.19% ################
12 11.75% ###########
13  7.50% #######
14  3.71% ###
15  1.51% #
16  0.48% 
17  0.13% 
18  0.03% </code></pre>

<p>10 is the most likely result, as you would expect, although other outcomes are possible too. This distribution spells out exactly how probable each outcome is.</p>

<p>This distribution also looks a lot like the normal distribution, and in fact as <code>n</code> increases, the binomial distribution approximates the normal distribution.</p>

<p>The probability density function involves some combinatorics, which is not entirely surprising.</p>
<script type='math/tex; mode=display'>
f(k) = {n \choose k}p^k(1-p)^{n-k}
</script>
<p>The <a href='http://en.wikipedia.org/wiki/Geometric_distribution'>geometric distribution</a> can be modeled as the number of failures you will see before seeing your first success in repeated Bernoulli trials with bias <script type='math/tex'>p</script>. In other words, if I flip a coin repeatedly, how many tails will I see before get my first head?</p>
<div class='highlight'><pre><code class='scala'><span class='k'>def</span> <span class='n'>geometric</span><span class='o'>(</span><span class='n'>p</span><span class='k'>:</span> <span class='kt'>Double</span><span class='o'>)</span><span class='k'>:</span> <span class='kt'>Distribution</span><span class='o'>[</span><span class='kt'>Int</span><span class='o'>]</span> <span class='k'>=</span> <span class='o'>{</span>
  <span class='n'>bernoulli</span><span class='o'>(</span><span class='n'>p</span><span class='o'>).</span><span class='n'>until</span><span class='o'>(</span><span class='k'>_</span><span class='o'>.</span><span class='n'>headOption</span> <span class='o'>==</span> <span class='nc'>Some</span><span class='o'>(</span><span class='kc'>true</span><span class='o'>)).</span><span class='n'>map</span><span class='o'>(</span><span class='k'>_</span><span class='o'>.</span><span class='n'>size</span> <span class='o'>-</span> <span class='mi'>1</span><span class='o'>)</span>
<span class='o'>}</span>
</code></pre></div>
<pre><code>scala&gt; geometric(0.5).hist
 0 49.56% #################################################
 1 25.83% #########################
 2 12.06% ############
 3  6.23% ######
 4  3.08% ###
 5  1.68% #
 6  0.75% 
 7  0.40% 
 8  0.21% 
 9  0.10% 
10  0.04% 
11  0.04% 
12  0.02% </code></pre>

<p>Half the time heads comes up right away, a quarter of the time it comes up on the second flip, an eighth of the time it comes up on the 3rd flip, etc. <script type='math/tex'>\frac{1}{2}, \frac{1}{4}, \frac{1}{8}, ..., (\frac{1}{2})^n</script> is a geometric series and that&#8217;s where this distribution gets its name. If you used a biased coin, you would get a different (but still geometric) series.</p>
    </div>

    

    

    <hr>
    <div class="navigation">
    
    
      <div style="clear: both"></div>
    </div>
    <hr>
    


  <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_developer = 1;
    var disqus_shortname = 'jliszka'; // required: replace example with your forum shortname
    
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">blog comments powered by <span class="logo-disqus">Disqus</span></a>




  </div>
</div>


      </div>
      <hr>
      <footer>
        <p>&copy; 2013 Jason Liszka
          with help from <a href="http://jekyllbootstrap.com" target="_blank" title="The Definitive Jekyll Blogging Framework">Jekyll Bootstrap</a>
          and <a href="http://twitter.github.com/bootstrap/" target="_blank">Twitter Bootstrap</a>
        </p>
      </footer>

    </div>

    
  </body>
</html>

